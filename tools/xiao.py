import json
import sys
import hashlib
import os

# jar è·¯å¾„ï¼ˆç”¨äºè®¡ç®— md5ï¼‰
primary_jar_path = "jar/spider.jar"
fallback_jar_path = "../xiaosa/spider.jar"

# éœ€è¦åˆ é™¤çš„ç«™ç‚¹ keyï¼ˆåœ¨æ­¤å¡«å†™å³å¯åˆ é™¤ï¼‰
remove_keys = {"ç‰ˆæœ¬ä¿¡æ¯","è…¾è®¯è§†é¢‘","ä¼˜é…·è§†é¢‘","èŠ’æœè§†é¢‘","çˆ±å¥‡è‰º","ä¸‰å…­é›¶","è±†ç“£","push_agent","é…ç½®ä¸­å¿ƒ","æœ¬åœ°","é¢„å‘Š"}   # å¯ä»¥åŠ å¤šä¸ªï¼Œä¾‹å¦‚ {"å·´å£«åŠ¨æ¼«", "ç”µå½±ç‰›"}

# ä¿å­˜ JSON æ–‡ä»¶ï¼ˆæŠ˜å å­—å…¸æ•°ç»„ä¸ºå•è¡Œï¼Œç©ºæ•°ç»„å’ŒåŸºç¡€æ•°ç»„ä¸€è¡Œï¼‰
class CompactJSONEncoder(json.JSONEncoder):
    def iterencode(self, o, _one_shot=False):
        def _compact_list(lst, indent_level):
            pad = '  ' * indent_level
            if not lst or all(isinstance(i, (str, int, float, bool, type(None))) for i in lst):
                return json.dumps(lst, ensure_ascii=False)
            if all(isinstance(i, dict) for i in lst):
                return '[\n' + ',\n'.join([pad + '  ' + json.dumps(i, ensure_ascii=False, separators=(',', ': ')) for i in lst]) + '\n' + pad + ']'
            return json.dumps(lst, ensure_ascii=False, indent=2)

        def _encode(obj, indent_level=0):
            pad = '  ' * indent_level
            if isinstance(obj, dict):
                lines = [f'"{k}": {_encode(v, indent_level+1)}' for k, v in obj.items()]
                return '{\n' + pad + '  ' + (',\n' + pad + '  ').join(lines) + '\n' + pad + '}'
            elif isinstance(obj, list):
                return _compact_list(obj, indent_level)
            return json.dumps(obj, ensure_ascii=False)

        return iter([_encode(o)])


def fetch_json(path_or_url):
    if os.path.exists(path_or_url):
        with open(path_or_url, "r", encoding="utf-8") as f:
            return json.load(f)
    raise ValueError(f"æ— æ•ˆè·¯å¾„æˆ– URLï¼š{path_or_url}")


def get_md5(filepath):
    md5 = hashlib.md5()
    with open(filepath, "rb") as f:
        while chunk := f.read(8192):
            md5.update(chunk)
    return md5.hexdigest()

def replace_drpy_path(site):
    """å°† ./js/drpy2.min.js æ›¿æ¢ä¸º ./lib/drpy2.min.js"""
    if not isinstance(site, dict):
        return
    for field in ("api", "ext"):
        val = site.get(field)
        if isinstance(val, str) and val == "./js/drpy2.min.js":
            site[field] = "./lib/drpy2.min.js"




def insert_sites_at_key(base_sites, insert_sites, key_marker):
    for i, item in enumerate(base_sites):
        if item.get("key") == key_marker:
            return base_sites[:i + 1] + insert_sites + base_sites[i + 1:]
    print(f"âš ï¸ æœªæ‰¾åˆ° key ä¸º {key_marker} çš„æ’å…¥ç‚¹ï¼Œè¿½åŠ åˆ°æœ«å°¾")
    return base_sites + insert_sites


def remove_sites(sites, keys_to_remove):
    """ä»ç«™ç‚¹åˆ—è¡¨ä¸­åˆ é™¤æŒ‡å®š key çš„ç«™ç‚¹"""
    return [s for s in sites if s.get("key") not in keys_to_remove]


def dedupe_by_name(base_sites, insert_sites):
    """æŒ‰ name å»é‡ï¼šè‹¥é‡åï¼Œä¼˜å…ˆä¿ç•™ base_sites ä¸­çš„æ¡ç›®"""
    base_names = {s.get("name") for s in base_sites if isinstance(s, dict)}
    return [s for s in insert_sites if s.get("name") not in base_names]


if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python xiao.py <æœ¬åœ°api.jsonè·¯å¾„> <æœ¬åœ°dianshi.jsonè·¯å¾„>")
        print("ç¤ºä¾‹: python xiao.py ../xiaosa/api.json dianshi.json")
        sys.exit(1)

    remote_url = sys.argv[1]
    local_file = sys.argv[2]

    # 1. ä¸‹è½½è¿œç¨‹ JSON
    data = fetch_json(remote_url)

    # 2. è¯»å– sitesï¼ˆä¸å†ç­›é€‰ï¼‰
    sites = data.get("sites", [])
    filtered_sites = [s for s in sites if isinstance(s, dict)]

    # 3. ä¸å†å•ç‹¬è¿½åŠ  XYQHikerï¼ˆå·²åŒ…å«åœ¨ sites ä¸­ï¼‰

    # 3.1 ä¸åˆ é™¤ç«™ç‚¹ï¼Œä»…ç§»é™¤æ¯ä¸ªç«™ç‚¹çš„ jar å­—æ®µ
    before_count = len(filtered_sites)
    removed_sites = []
    for site in filtered_sites:
        replace_drpy_path(site)
        if isinstance(site, dict) and "jar" in site:
            site.pop("jar", None)
    removed_count = before_count - len(filtered_sites)
    print(f"âœ… æ›´æ–° {len(filtered_sites)} ä¸ªç«™ç‚¹")

    # 4. è¯»å–æœ¬åœ°æ–‡ä»¶
    with open(local_file, "r", encoding="utf-8") as f:
        dianshi = json.load(f)

    # 5. æ’å…¥åˆ° key="cbh" ä¹‹åï¼ˆæŒ‰ name å»é‡ï¼Œä¿ç•™æœ¬åœ°ï¼‰
    dianshi_sites = dianshi.get("sites", [])
    # å…ˆæŒ‰ key åˆ é™¤æ¥æºç«™ç‚¹
    if remove_keys:
        filtered_sites = [s for s in filtered_sites if s.get("key") not in remove_keys]
    filtered_sites = dedupe_by_name(dianshi_sites, filtered_sites)
    dianshi["sites"] = insert_sites_at_key(dianshi_sites, filtered_sites, "cbh")

    # 6. åˆ é™¤æŒ‡å®šçš„ç«™ç‚¹
    # before_count = len(dianshi["sites"])
    # dianshi["sites"] = remove_sites(dianshi["sites"], remove_keys)
    # after_count = len(dianshi["sites"])
    # print(f"âœ… åˆ é™¤äº† {before_count - after_count} ä¸ªæŒ‡å®šç«™ç‚¹: {', '.join(remove_keys)}")

    # 7. è®¾ç½® spider ä¸º jar+md5ï¼ˆç»Ÿä¸€åœ¨è¾“å‡ºæ–‡ä»¶ä¸­ï¼‰
    jar_path = primary_jar_path if os.path.exists(primary_jar_path) else fallback_jar_path
    if os.path.exists(jar_path):
        md5_val = get_md5(jar_path)
        dianshi["spider"] = f"./jar/spider.jar;md5;{md5_val}"
        print(f"ğŸ”„ spider å·²æ›´æ–°ä¸º: {dianshi['spider']}")
    else:
        print(f"âš ï¸ æ‰¾ä¸åˆ° jar æ–‡ä»¶ï¼Œæœªæ›´æ–° spiderï¼š{primary_jar_path} / {fallback_jar_path}")

    # 8. ä¿å­˜åˆå¹¶ç»“æœï¼ˆæ–°æ–‡ä»¶ï¼‰
    output_file = f"{local_file.rsplit('.',1)[0]}_with_app_sites.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(dianshi, f, ensure_ascii=False, indent=2, cls=CompactJSONEncoder)

    print(f"âœ… åˆå¹¶å®Œæˆï¼Œå·²ä¿å­˜ä¸º {output_file}")
